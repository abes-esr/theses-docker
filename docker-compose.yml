# Configuration docker pour déployer theses.fr
# avant de lancer docker-compose up, il est nécessaire
# de copier le fichier .env-dist dans le fichier .env
# puis de personnaliser le contenu du fichier .env
version: "3.5"

services:

  # theses-rp est le reverse proxy application de theses.fr
  # toutes les requêtes HTTP passent par lui, il est chargé
  # d'authentifier les utilisateurs avec la fédération d'identités
  # RENATER lorsque ce derniers accèdent à /74979_GERARDIN_2018_archivage.pdf
  # (à adapter)
  theses-rp:
    container_name: theses-rp
    image: abesesr/docker-shibboleth-renater-sp:1.4.0
    ports:
      - ${THESES_RP_HTTPS_PORT}:443
      - ${THESES_RP_HTTP_PORT}:80
    environment:
      RENATER_SP_TEST_OR_PROD: ${RENATER_SP_TEST_OR_PROD}
      RENATER_SP_ENTITY_ID: ${RENATER_SP_ENTITY_ID}
      RENATER_SP_ADMIN_MAIL: ${RENATER_SP_ADMIN_MAIL}
      RENATER_SP_HTTPD_SERVER_NAME: ${RENATER_SP_HTTPD_SERVER_NAME}
      RENATER_SP_HTTPD_LOG_LEVEL: "info ssl:warn"
      RENATER_SP_HTTPD_LOG_FORMAT: '%h \"%{Shib-Identity-Provider}i\" \"%{eppn}i\" \"%{primary-affiliation}i\" \"%{supannEtablissement}i\" %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-Agent}i\"'
      RENATER_SP_HTTPD_PUBLIC_PATH_0: "/"
      RENATER_SP_HTTPD_PUBLIC_PROXY_TO_0: "http://theses-front:80/"
      RENATER_SP_HTTPD_PUBLIC_PATH_1: "/poc-fede/"
      RENATER_SP_HTTPD_PUBLIC_PROXY_TO_1: "http://theses-api-diffusion:80/poc-fede/"
      RENATER_SP_HTTPD_PUBLIC_PATH_2: "/api/v1/recherche/"
      RENATER_SP_HTTPD_PUBLIC_PROXY_TO_2: "http://theses-api-recherche:80/api/v1/recherche/"
      RENATER_SP_HTTPD_PUBLIC_PATH_3: "/kibana/"
      RENATER_SP_HTTPD_PUBLIC_PROXY_TO_3: "http://theses-kibana:5601/"
      RENATER_SP_HTTPD_PROTECTED_PATH_0: "/poc-fede/74979_GERARDIN_2018_archivage.pdf"
      RENATER_SP_HTTPD_PROTECTED_PROXY_TO_0: "http://theses-api-diffusion/poc-fede/74979_GERARDIN_2018_archivage.pdf"
    volumes:
      - ./volumes/theses-rp/shibboleth/ssl/:/etc/shibboleth/ssl/
    restart: unless-stopped
    # Ces commentaires sont conservés pour expliquer pourquoi theses-rp ne dépend pas des autres conteneurs
    # la raison est que theses-rp est relativement long à démarrer (plusieurs minutes) et qu'il ne sera que
    # très rarrement mis à jour, donc autant ne pas le redémarrer si jamais une de ses dépendance redémarre.
    #depends_on:
    #  - theses-api-diffusion
    #  - theses-api-recherche
    #  - theses-front
    labels:
      # pour envoyer les logs dans le puits de log de l'abes
      - "co.elastic.logs/enabled=true"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=theses"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=apache"



  # Interface utilisateur de theses.fr (dévelopée en VueJS)
  theses-front:
    container_name: theses-front
    image: abesesr/theses:${THESES_FRONT_VERSION}
    restart: unless-stopped
    ports:
      - ${THESES_FRONT_HTTP_PORT}:80
    depends_on:
      - theses-api-diffusion
      - theses-api-recherche
    labels:
      # pour envoyer les logs dans le puits de log de l'abes
      - "co.elastic.logs/enabled=true"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=theses"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=nginx"



  # API de diffusion des thèses en java spring de theses.fr
  # (travail en cours, pour la preuve de concept il est
  #  chargé de mettre à disposition un PDF en 
  #  accès restreint que theses-rp protège)
  theses-api-diffusion:
    container_name: theses-api-diffusion
    #image: mendhak/http-https-echo:23
    build: ./images/theses-api-diffusion/
    image: httpd:2.4.54-theses-api-diffusion
    restart: unless-stopped
    labels:
      # pour envoyer les logs dans le puits de log de l'abes
      - "co.elastic.logs/enabled=true"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=theses"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=apache"



  # API de recherche des thèses qui fait l'intermédiaire avec elasticsearch
  theses-api-recherche:
    container_name: theses-api-recherche
    # TODO : à remplacer par sa version en java spring
    build: ./images/theses-api-recherche/
    image: abesesr/theses:develop-api-recherche
    restart: unless-stopped
    environment:
      ELASTICSEARCH_HOST_PROXY_TO: "http://theses-elasticsearch-01:${ELK_ELASTIC_HTTP_PORT}/"
    depends_on:
      theses-elasticsearch:
        condition: service_healthy
    labels:
      # pour envoyer les logs dans le puits de log de l'abes
      - "co.elastic.logs/enabled=true"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=theses"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=apache"




  # batch pour indexer les 11 thèses dans elasticsearch
  # (travail en cours pour la preuve de concept de l'indexation de 11 thèses)
  theses-batch-11theses:
    container_name: theses-batch-11theses
    depends_on:
      theses-elasticsearch:
        condition: service_healthy
    build: ./images/theses-batch/
    image: abesesr/theses:develop-batch
    environment:
      ELASTICSEARCH_HOST: "http://theses-elasticsearch-01:${ELK_ELASTIC_HTTP_PORT}"
    command: /app/theses-sample-load.sh
    labels:
      # pour envoyer les logs dans le puits de log de l'abes
      - "co.elastic.logs/enabled=true"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=theses"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=adhoc"



  # theses-elasticsearch-01
  # noeud numéro1 d'elasticsearch (en local c'est l'unique noeud qui est lancé)
  theses-elasticsearch:
    container_name: theses-elasticsearch-${ELK_CLUSTER_NODE_NUMBER}
    image: docker.elastic.co/elasticsearch/elasticsearch:${ELK_STACK_VERSION}
    volumes:
      - ./volumes/theses-elasticsearch/:/usr/share/elasticsearch/data/
    ports:
      # réglage explicites des ports internes et externes pour pouvoir fonctionner en cluster
      # cf https://blog.cri.epita.fr/post/2019-06-10-elasticsearch-cluster-formation-issue/
      - ${ELK_ELASTIC_HTTP_PORT}:${ELK_ELASTIC_HTTP_PORT}
      - ${ELK_ELASTIC_TRANSPORT_PORT}:${ELK_ELASTIC_TRANSPORT_PORT}
    environment:
      # réglage explicites des ports internes et externes pour pouvoir fonctionner en cluster
      # cf https://blog.cri.epita.fr/post/2019-06-10-elasticsearch-cluster-formation-issue/
      - http.port=${ELK_ELASTIC_HTTP_PORT}
      - transport.port=${ELK_ELASTIC_TRANSPORT_PORT}
      - network.publish_host=${ELK_CLUSTER_PUBLISH_HOST}
      # paramétrage du cluster elasticsearch
      - node.name=theses-es${ELK_CLUSTER_NODE_NUMBER}
      - cluster.name=${ELK_CLUSTER_NAME}
      - cluster.initial_master_nodes=${ELK_CLUSTER_INITIAL_MASTER_NODES}
      - discovery.seed_hosts=${ELK_CLUSTER_DISCOVER_SEED_HOSTS}
      - bootstrap.memory_lock=true
      # paramètres de sécurité d'elasticsearch
      - xpack.security.enabled=false
      - xpack.license.self_generated.type=${ELK_LICENSE}
    mem_limit: ${ELK_MEM_LIMIT}
    ulimits:
      memlock:
        soft: -1
        hard: -1
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s http://localhost:${ELK_ELASTIC_HTTP_PORT} | grep -q 'cluster_name'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120
    labels:
      # pour envoyer les logs dans le puits de log de l'abes
      - "co.elastic.logs/enabled=true"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=theses"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=elasticsearch"



  # theses-kibana
  # kibana est le backoffice de l'elasticsearch de theses.fr
  theses-kibana:
    container_name: theses-kibana
    depends_on:
      theses-elasticsearch:
        condition: service_healthy
    image: docker.elastic.co/kibana/kibana:${ELK_STACK_VERSION}
    volumes:
      - ./volumes/theses-kibana/:/usr/share/kibana/data/
    ports:
      - ${ELK_KIBANA_PORT}:5601
    environment:
      - SERVERNAME=kibana
      - SERVER_BASEPATH=/kibana
      - ELASTICSEARCH_HOSTS=http://theses-elasticsearch-01:${ELK_ELASTIC_HTTP_PORT}
    mem_limit: ${ELK_MEM_LIMIT}
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s -I http://localhost:5601 | grep -q 'HTTP/1.1 302 Found'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120
    labels:
      # pour envoyer les logs dans le puits de log de l'abes
      - "co.elastic.logs/enabled=true"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=theses"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=kibana"



# Cette configuration peut être décommentée pour pouvoir monter un cluster local elasticsearch
# elle permet de lancer plusieurs noeuds indépendants au niveau docker mais reliés par ce réseau commun
# pour lancer deux noeuds sur la même machine, il suffit alors de :
# 1) créer ce réseau via "docker network create theses-docker-es-cluster-network"
# 2) pour le noeud 2 utiliser la config suivante : https://github.com/abes-esr/theses-es-cluster-docker/
# 3) paramétrer le .env de chaque noeud avec ELK_CLUSTER_NODE_NUMBER qui vaut "01" ou "02" (fonction du noeud) :
#    ELK_CLUSTER_NODE_NUMBER=01
#    ELK_CLUSTER_DISCOVER_SEED_HOSTS=theses-elasticsearch-01:9300,theses-elasticsearch-02:9300
#    ELK_CLUSTER_INITIAL_MASTER_NODES=theses-es01,theses-es02
# 4) lancer les deux noeuds dans leurs deux répertoires dédié avec "docker-compose up"
#networks:
#  default:
#    name: theses-docker-es-cluster-network
#    external: true

