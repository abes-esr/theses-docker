# Configuration docker pour déployer theses.fr
# avant de lancer docker-compose up, il est nécessaire
# de copier le fichier .env-dist dans le fichier .env
# puis de personnaliser le contenu du fichier .env
version: "3.5"

services:

  #######################################
  # theses-rp
  # le reverse proxy applicatif de theses.fr
  # toutes les requêtes HTTP passent par lui, il est chargé
  # d'authentifier les utilisateurs avec la fédération d'identités
  # RENATER lorsque ce derniers accèdent à /74979_GERARDIN_2018_archivage.pdf
  # (à adapter)
  theses-rp:
    container_name: theses-rp
    image: abesesr/docker-shibboleth-renater-sp:1.5.1
    ports:
      - ${THESES_RP_HTTPS_PORT}:443
      - ${THESES_RP_HTTP_PORT}:80
    environment:
      RENATER_SP_TEST_OR_PROD: ${RENATER_SP_TEST_OR_PROD}
      RENATER_SP_ENTITY_ID: ${RENATER_SP_ENTITY_ID}
      RENATER_SP_ADMIN_MAIL: ${RENATER_SP_ADMIN_MAIL}
      RENATER_SP_HTTPD_SERVER_NAME: ${RENATER_SP_HTTPD_SERVER_NAME}
      RENATER_SP_HTTPD_LOG_LEVEL: "info ssl:warn"
      RENATER_SP_HTTPD_LOG_FORMAT: '%h \"%{Shib-Identity-Provider}i\" \"%{eppn}i\" \"%{primary-affiliation}i\" \"%{supannEtablissement}i\" %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-Agent}i\"'
      RENATER_SP_HTTPD_PUBLIC_PATH_0: "/"
      RENATER_SP_HTTPD_PUBLIC_PROXY_TO_0: "http://theses-front:80/"
      RENATER_SP_HTTPD_PUBLIC_PATH_1: "/poc-fede/"
      RENATER_SP_HTTPD_PUBLIC_PROXY_TO_1: "http://theses-api-diffusion:80/poc-fede/"
      RENATER_SP_HTTPD_PUBLIC_PATH_2: "/api/v1/recherche/"
      RENATER_SP_HTTPD_PUBLIC_PROXY_TO_2: "http://theses-api-recherche:80/api/v1/recherche/"
      RENATER_SP_HTTPD_PROTECTED_PATH_0: "/poc-fede/74979_GERARDIN_2018_archivage.pdf"
      RENATER_SP_HTTPD_PROTECTED_PROXY_TO_0: "http://theses-api-diffusion/poc-fede/74979_GERARDIN_2018_archivage.pdf"
      # pour -prod ELK_KIBANA_PROTECTED_PATH est renseigné mais ELK_KIBANA_PUBLIC_PATH est vide
      RENATER_SP_HTTPD_PROTECTED_PATH_1: ${ELK_KIBANA_PROTECTED_PATH}
      RENATER_SP_HTTPD_PROTECTED_PROXY_TO_1: "http://theses-kibana:5601/"
      RENATER_SP_HTTPD_PROTECTED_REQUIRE_1_0: "Require shib-attr Shib-Identity-Provider https://ciboulette.abes.fr/idp/shibboleth"
      # pour -local -dev -test mais pour -prod ELK_KIBANA_PUBLIC_PATH est vide et c'est ELK_KIBANA_PROTECTED_PATH qui est renseigné
      RENATER_SP_HTTPD_PUBLIC_PATH_3: ${ELK_KIBANA_PUBLIC_PATH}
      RENATER_SP_HTTPD_PUBLIC_PROXY_TO_3: "http://theses-kibana:5601/"
    volumes:
      - ./volumes/theses-rp/shibboleth/ssl/:/etc/shibboleth/ssl/
    restart: unless-stopped
    # Ces commentaires sont conservés pour expliquer pourquoi theses-rp ne dépend pas des autres conteneurs
    # la raison est que theses-rp est relativement long à démarrer (plusieurs minutes) et qu'il ne sera que
    # très rarrement mis à jour, donc autant ne pas le redémarrer si jamais une de ses dépendance redémarre.
    #depends_on:
    #  - theses-api-diffusion
    #  - theses-api-recherche
    #  - theses-front
    labels:
      # pour envoyer les logs dans le puits de log de l'abes
      - "co.elastic.logs/enabled=true"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=theses"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=apache"



  #######################################
  # theses-front
  # Interface utilisateur de theses.fr (dévelopée en VueJS)
  theses-front:
    container_name: theses-front
    image: abesesr/theses:${THESES_FRONT_VERSION}
    restart: unless-stopped
    ports:
      - ${THESES_FRONT_HTTP_PORT}:80
    depends_on:
      - theses-api-diffusion
      - theses-api-recherche
    labels:
      # pour envoyer les logs dans le puits de log de l'abes
      - "co.elastic.logs/enabled=true"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=theses"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=nginx"
      # pour que les mises à jour de cette image soient auto-déployées
      # par watchtower cf docker-compose.watchtower.yml
      - "com.centurylinklabs.watchtower.scope=theses-watchtower-scope"   


  #######################################
  # theses-api-diffusion
  # API de diffusion des thèses en java spring de theses.fr
  # (travail en cours, pour la preuve de concept il est
  #  chargé de mettre à disposition un PDF en 
  #  accès restreint que theses-rp protège)
  theses-api-diffusion:
    container_name: theses-api-diffusion
    #image: mendhak/http-https-echo:23
    build: ./images/theses-api-diffusion/
    image: httpd:2.4.54-theses-api-diffusion
    restart: unless-stopped
    labels:
      # pour envoyer les logs dans le puits de log de l'abes
      - "co.elastic.logs/enabled=true"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=theses"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=apache"



  #######################################
  # theses-api-recherche
  # API de recherche de theses.fr qui fait entre autre l'intermédiaire avec elasticsearch
  # (travail en cours car sera remplacé par du Java Sprint ensuite)
  theses-api-recherche:
    container_name: theses-api-recherche
    # TODO : à remplacer par sa version en java spring
    build: ./images/theses-api-recherche/
    image: abesesr/theses:develop-api-recherche
    restart: unless-stopped
    environment:
      THESES_API_RECHERCHE_ELASTIC_USERNAME: ${THESES_API_RECHERCHE_ELASTIC_USERNAME}
      THESES_API_RECHERCHE_ELASTIC_PASSWORD: ${THESES_API_RECHERCHE_ELASTIC_PASSWORD}
      ELASTICSEARCH_HOST_PROXY_TO: "https://theses-elasticsearch-01:${ELK_ELASTIC_HTTP_PORT}/"
    depends_on:
      theses-elasticsearch:
        condition: service_healthy
    labels:
      # pour envoyer les logs dans le puits de log de l'abes
      - "co.elastic.logs/enabled=true"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=theses"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=apache"



  #######################################
  # theses-batch-11theses
  # batch pour indexer les 11 thèses dans elasticsearch
  # (travail en cours pour la preuve de concept de l'indexation de 11 thèses)
  theses-batch-11theses:
    container_name: theses-batch-11theses
    depends_on:
      theses-elasticsearch:
        condition: service_healthy
    build: ./images/theses-batch/
    image: abesesr/theses:develop-batch
    environment:
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD}
      ELASTICSEARCH_HOST: "https://theses-elasticsearch-01:${ELK_ELASTIC_HTTP_PORT}"
    command: /app/theses-sample-load.sh
    labels:
      # pour envoyer les logs dans le puits de log de l'abes
      - "co.elastic.logs/enabled=true"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=theses"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=adhoc"



  #######################################
  # theses-elasticsearch-setupcerts
  # conteneur chargé de
  # - configurer les certificats pour que les X noeuds elasticsearch communiquent entre eux de façon sécurisé
  # - créer les différents comptes applicatifs pour accès à elasticsearch
  theses-elasticsearch-setupcerts:
    container_name: theses-elasticsearch-setupcerts
    image: docker.elastic.co/elasticsearch/elasticsearch:${ELK_STACK_VERSION}
    volumes:
      - ./volumes/theses-elasticsearch-setupcerts/:/usr/share/elasticsearch/config/certs/
    user: "0"
    environment:
      KIBANA_PASSWORD: ${KIBANA_PASSWORD}
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD}
      ELK_ELASTIC_HTTP_PORT: ${ELK_ELASTIC_HTTP_PORT}
      THESES_API_RECHERCHE_ELASTIC_USERNAME: ${THESES_API_RECHERCHE_ELASTIC_USERNAME} 
      THESES_API_RECHERCHE_ELASTIC_PASSWORD: ${THESES_API_RECHERCHE_ELASTIC_PASSWORD} 
    command: >
      bash -c '
        if [ x${ELASTIC_PASSWORD} == x ]; then
          echo "Set the ELASTIC_PASSWORD environment variable in the .env file";
          exit 1;
        elif [ x${KIBANA_PASSWORD} == x ]; then
          echo "Set the KIBANA_PASSWORD environment variable in the .env file";
          exit 1;
        fi;
        if [ ! -f config/certs/ca.zip ]; then
          echo "Creating CA";
          bin/elasticsearch-certutil ca --silent --pem -out config/certs/ca.zip;
          unzip -o config/certs/ca.zip -d config/certs;
        fi;
        if [ ! -f config/certs/certs.zip ]; then
          echo "Creating certs";
          echo -ne \
          "instances:\n"\
          "  - name: es01\n"\
          "    dns:\n"\
          "      - theses-elasticsearch-01\n"\
          "      - localhost\n"\
          "    ip:\n"\
          "      - 127.0.0.1\n"\
          "  - name: es02\n"\
          "    dns:\n"\
          "      - theses-elasticsearch-02\n"\
          "      - localhost\n"\
          "    ip:\n"\
          "      - 127.0.0.1\n"\
          "  - name: es03\n"\
          "    dns:\n"\
          "      - theses-elasticsearch-03\n"\
          "      - localhost\n"\
          "    ip:\n"\
          "      - 127.0.0.1\n"\
          "  - name: es04\n"\
          "    dns:\n"\
          "      - theses-elasticsearch-04\n"\
          "      - localhost\n"\
          "    ip:\n"\
          "      - 127.0.0.1\n"\
          > config/certs/instances.yml;
          bin/elasticsearch-certutil cert --silent --pem -out config/certs/certs.zip --in config/certs/instances.yml --ca-cert config/certs/ca/ca.crt --ca-key config/certs/ca/ca.key;
          unzip -o config/certs/certs.zip -d config/certs;
        fi;
        echo "Setting file permissions"
        chown -R root:root config/certs;
        find . -type d -exec chmod 750 \{\} \;;
        find . -type f -exec chmod 640 \{\} \;;
        echo "Waiting for Elasticsearch availability (status=green)";
        until curl -s --cacert config/certs/ca/ca.crt -u elastic:${ELASTIC_PASSWORD} https://theses-elasticsearch-01:${ELK_ELASTIC_HTTP_PORT}/_cluster/health?timeout=5s | grep -v -q '\"status\":\"green\"'; do sleep 10; done;
        echo "Setting kibana_system password";
        until curl -s -X POST --cacert config/certs/ca/ca.crt -u elastic:${ELASTIC_PASSWORD} -H "Content-Type: application/json" https://theses-elasticsearch-01:${ELK_ELASTIC_HTTP_PORT}/_security/user/kibana_system/_password -d "{\"password\":\"${KIBANA_PASSWORD}\"}" | grep -q "^{}"; do sleep 10; done;
        echo "Setting theses-api-recherche password";
        until curl -s -X POST --cacert config/certs/ca/ca.crt -u elastic:${ELASTIC_PASSWORD} -H "Content-Type: application/json" https://theses-elasticsearch-01:${ELK_ELASTIC_HTTP_PORT}/_security/user/${THESES_API_RECHERCHE_ELASTIC_USERNAME} -d "{\"password\":\"${THESES_API_RECHERCHE_ELASTIC_PASSWORD}\", \"enabled\": true, \"roles\":[\"viewer\"], \"full_name\":\"\", \"email\":\"\"}" | grep -q "^{\"created\":"; do sleep 10; done;
        echo "All done!";
      '
    healthcheck:
      test: ["CMD-SHELL", "[ -f config/certs/es01/es01.crt ]"]
      interval: 1s
      timeout: 5s
      retries: 120
    labels:
      # pour envoyer les logs dans le puits de log de l'abes
      - "co.elastic.logs/enabled=true"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=theses"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=adhoc"



  #######################################
  # theses-elasticsearch
  # noeud n°1 de l'elasticsearch de theses.fr
  # Ref. https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html
  # cf https://github.com/abes-esr/theses-es-cluster-docker#readme pour le mode cluster
  theses-elasticsearch:
    container_name: theses-elasticsearch-${ELK_CLUSTER_NODE_NUMBER}
    depends_on:
      theses-elasticsearch-setupcerts:
        condition: service_healthy
    image: docker.elastic.co/elasticsearch/elasticsearch:${ELK_STACK_VERSION}
    restart: unless-stopped
    volumes:
      - ./volumes/theses-elasticsearch-setupcerts/:/usr/share/elasticsearch/config/certs/
      - ./volumes/theses-elasticsearch/:/usr/share/elasticsearch/data/
    ports:
      # réglage explicites des ports internes et externes pour pouvoir fonctionner en cluster
      # cf https://blog.cri.epita.fr/post/2019-06-10-elasticsearch-cluster-formation-issue/
      - ${ELK_ELASTIC_HTTP_PORT}:${ELK_ELASTIC_HTTP_PORT}
      - ${ELK_ELASTIC_TRANSPORT_PORT}:${ELK_ELASTIC_TRANSPORT_PORT}
    environment:
      # mot de passe superadmin correspondant au login "elastic"
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      # réglage explicites des ports internes et externes pour pouvoir fonctionner en cluster
      # cf https://blog.cri.epita.fr/post/2019-06-10-elasticsearch-cluster-formation-issue/
      - http.port=${ELK_ELASTIC_HTTP_PORT}
      - transport.port=${ELK_ELASTIC_TRANSPORT_PORT}
      - network.publish_host=${ELK_CLUSTER_PUBLISH_HOST}
      # paramétrage du cluster elasticsearch
      - node.name=theses-es${ELK_CLUSTER_NODE_NUMBER}
      - cluster.name=${ELK_CLUSTER_NAME}
      - cluster.initial_master_nodes=${ELK_CLUSTER_INITIAL_MASTER_NODES}
      - discovery.seed_hosts=${ELK_CLUSTER_DISCOVER_SEED_HOSTS}
      - bootstrap.memory_lock=true
      # paramètres de sécurité d'elasticsearch
      - xpack.security.enabled=true
      - xpack.security.http.ssl.enabled=true
      - xpack.security.http.ssl.key=certs/es${ELK_CLUSTER_NODE_NUMBER}/es${ELK_CLUSTER_NODE_NUMBER}.key
      - xpack.security.http.ssl.certificate=certs/es${ELK_CLUSTER_NODE_NUMBER}/es${ELK_CLUSTER_NODE_NUMBER}.crt
      - xpack.security.http.ssl.certificate_authorities=certs/ca/ca.crt
      - xpack.security.http.ssl.verification_mode=certificate
      - xpack.security.transport.ssl.enabled=true
      - xpack.security.transport.ssl.key=certs/es${ELK_CLUSTER_NODE_NUMBER}/es${ELK_CLUSTER_NODE_NUMBER}.key
      - xpack.security.transport.ssl.certificate=certs/es${ELK_CLUSTER_NODE_NUMBER}/es${ELK_CLUSTER_NODE_NUMBER}.crt
      - xpack.security.transport.ssl.certificate_authorities=certs/ca/ca.crt
      - xpack.security.transport.ssl.verification_mode=certificate
      - xpack.license.self_generated.type=${ELK_LICENSE}
    mem_limit: ${ELK_MEM_LIMIT}
    ulimits:
      memlock:
        soft: -1
        hard: -1
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s --cacert config/certs/ca/ca.crt -u elastic:${ELASTIC_PASSWORD} 'https://localhost:${ELK_ELASTIC_HTTP_PORT}/_cluster/health?timeout=5s' | grep -q '\"status\":\"green\"'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120
    labels:
      # pour envoyer les logs dans le puits de log de l'abes
      - "co.elastic.logs/enabled=true"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=theses"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=elasticsearch"



  #######################################
  # theses-kibana
  # kibana est le backoffice de l'elasticsearch de theses.fr
  theses-kibana:
    container_name: theses-kibana
    depends_on:
      theses-elasticsearch:
        condition: service_healthy
    image: docker.elastic.co/kibana/kibana:${ELK_STACK_VERSION}
    restart: unless-stopped
    volumes:
      - ./volumes/theses-elasticsearch-setupcerts/:/usr/share/kibana/config/certs/
      - ./volumes/theses-kibana/:/usr/share/kibana/data/
    environment:
      SERVER_BASEPATH: "/kibana"
      ELASTICSEARCH_HOSTS: "https://theses-elasticsearch-01:${ELK_ELASTIC_HTTP_PORT}"
      ELASTICSEARCH_USERNAME: "kibana_system"
      ELASTICSEARCH_PASSWORD: ${KIBANA_PASSWORD}
      ELASTICSEARCH_SSL_CERTIFICATEAUTHORITIES: "config/certs/ca/ca.crt"
      xpack.reporting.roles.enabled: "false"
      XPACK_SECURITY_ENCRYPTIONKEY: ${ELK_KIBANA_SECURITY_ENCRYPTIONKEY}
      LOGGING_ROOT_LEVEL: "info" # ex: "info", "error", "warn", "fatal", "debug"
    mem_limit: ${ELK_MEM_LIMIT}
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s -I http://localhost:5601 | grep -q 'HTTP/1.1 302 Found'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120
    labels:
      # pour envoyer les logs dans le puits de log de l'abes
      - "co.elastic.logs/enabled=true"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=theses"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=kibana"



# Cette configuration peut être décommentée pour pouvoir monter un cluster local elasticsearch
# elle permet de lancer plusieurs noeuds indépendants au niveau docker mais reliés par ce réseau commun
# pour lancer deux noeuds sur la même machine, il suffit alors de :
# 1) créer ce réseau via "docker network create theses-docker-es-cluster-network"
# 2) pour le noeud 2 utiliser la config suivante : https://github.com/abes-esr/theses-es-cluster-docker/
# 3) paramétrer le .env de chaque noeud avec ELK_CLUSTER_NODE_NUMBER qui vaut "01" ou "02" (fonction du noeud) :
#    ELK_CLUSTER_NODE_NUMBER=01
#    ELK_CLUSTER_DISCOVER_SEED_HOSTS=theses-elasticsearch-01:9300,theses-elasticsearch-02:9300
#    ELK_CLUSTER_INITIAL_MASTER_NODES=theses-es01,theses-es02
# 4) lancer les deux noeuds dans leurs deux répertoires dédié avec "docker-compose up"
#networks:
#  default:
#    name: theses-docker-es-cluster-network
#    external: true

